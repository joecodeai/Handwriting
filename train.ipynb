{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "#https://huggingface.co/datasets/Teklia/IAM-line\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import pyarrow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(r\"D:\\Jupyter\\Handwriting\\IAM-line\\data\\train_processed.parquet\")\n",
    "test_df = pd.read_parquet(r\"D:\\Jupyter\\Handwriting\\IAM-line\\data\\test_processed.parquet\")\n",
    "val_df = pd.read_parquet(r\"D:\\Jupyter\\Handwriting\\IAM-line\\data\\validation_processed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_numpy(image_bytes):\n",
    "    try:\n",
    "        # Load the image\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        # Convert the image to a numpy array and scale to [0, 1]\n",
    "        image_array = np.array(image) / 255.0\n",
    "        return image_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process images one at a time\n",
    "for df in [train_df, test_df, val_df]:\n",
    "    for index, row in df.iterrows():\n",
    "        image_bytes = row['image']\n",
    "        df.at[index, 'image'] = convert_image_to_numpy(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>put down a resolution on the subject</td>\n",
       "      <td>[[0.9882352941176471, 0.9764705882352941, 0.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and he is to be backed by Mr. Will</td>\n",
       "      <td>[[0.9647058823529412, 0.9333333333333333, 0.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nominating any more Labour life Peers</td>\n",
       "      <td>[[0.984313725490196, 0.984313725490196, 0.9843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M Ps tomorrow. Mr. Michael Foot has</td>\n",
       "      <td>[[0.9529411764705882, 0.8666666666666667, 0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Griffiths, M P for Manchester Exchange .</td>\n",
       "      <td>[[0.984313725490196, 0.984313725490196, 0.9843...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text  \\\n",
       "0      put down a resolution on the subject   \n",
       "1        and he is to be backed by Mr. Will   \n",
       "2     nominating any more Labour life Peers   \n",
       "3       M Ps tomorrow. Mr. Michael Foot has   \n",
       "4  Griffiths, M P for Manchester Exchange .   \n",
       "\n",
       "                                               image  \n",
       "0  [[0.9882352941176471, 0.9764705882352941, 0.97...  \n",
       "1  [[0.9647058823529412, 0.9333333333333333, 0.93...  \n",
       "2  [[0.984313725490196, 0.984313725490196, 0.9843...  \n",
       "3  [[0.9529411764705882, 0.8666666666666667, 0.89...  \n",
       "4  [[0.984313725490196, 0.984313725490196, 0.9843...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.empty((len(train_df), 128, 2000), dtype=np.uint8)\n",
    "for i, image in enumerate(train_df['image'].values):\n",
    "    train_images[i] = image\n",
    "train_images = np.expand_dims(train_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 '\n",
    "char_to_num = {char: i for i, char in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def encode_text(text, max_len=32):\n",
    "    encoded = [char_to_num.get(char, len(char_to_num) - 1) for char in text]\n",
    "    return pad_sequences([encoded], maxlen=max_len, padding='post')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 80\n",
    "train_texts = np.stack(train_df['text'].apply(lambda x: encode_text(x, max_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(char_to_num)\n",
    "train_texts = tf.keras.utils.to_categorical(train_texts, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6482, 128, 2000, 1), (6482, 80, 63))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, train_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 128, 2000, 1)]    0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 2000, 32)     320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 1000, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 1000, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 1000, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 500, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 500, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 500, 128)      73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 250, 128)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 250, 128)     512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 80, 6400)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 80, 256)          6685696   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 80, 256)           0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 80, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 80, 128)          164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 80, 128)           0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 80, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 80, 63)            8127      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,953,279\n",
      "Trainable params: 6,952,063\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Dense, LSTM, Bidirectional, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_crnn_model(input_shape, num_classes):\n",
    "    input_img = Input(shape=input_shape, name='image_input')\n",
    "    \n",
    "    # Convolutional layers for feature extraction\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(input_img)\n",
    "    x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Adjust the pooling layers to achieve the desired sequence length\n",
    "    # Assuming the input shape is (128, 2000, 1)\n",
    "    # After the convolutions and max-pooling, the dimensions should be (16, 250, 128)\n",
    "    # We need to reshape to (80, *) for the LSTM layers\n",
    "    \n",
    "    # Reshape for LSTM layers\n",
    "    shape = tf.keras.backend.int_shape(x)\n",
    "    # Calculate the new shape\n",
    "    new_shape = (80, shape[1] * shape[2] * shape[3] // 80)\n",
    "    x = Reshape(target_shape=new_shape)(x)\n",
    "    \n",
    "    # Recurrent layers for sequence prediction\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Dense layer for character classification\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Number of classes for classification\n",
    "num_classes = 63\n",
    "\n",
    "# Create the model\n",
    "input_shape = (128, 2000, 1)\n",
    "crnn_model = create_crnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "crnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "crnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "203/203 [==============================] - 1894s 9s/step - loss: 2.3624 - accuracy: 0.4989\n",
      "Epoch 2/2\n",
      "203/203 [==============================] - 2123s 10s/step - loss: 1.8886 - accuracy: 0.5383\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    history = crnn_model.fit(\n",
    "        train_images, train_texts,\n",
    "        epochs=2, batch_size=32\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trial\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trial\\assets\n"
     ]
    }
   ],
   "source": [
    "crnn_model.save(\"trial\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
